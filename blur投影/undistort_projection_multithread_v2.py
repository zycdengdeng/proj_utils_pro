#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å»ç•¸å˜ç‰ˆæŠ•å½±ï¼šå¤šçº¿ç¨‹CPUä¼˜åŒ–ç‰ˆ V2 - bluræŠ•å½±ï¼ˆè·¯ä¾§ç€è‰²ï¼‰
ç»Ÿä¸€å˜æ¢é€»è¾‘ï¼šä¸–ç•Œåæ ‡ç³» â†’ LiDARåæ ‡ç³» â†’ ç›¸æœºåæ ‡ç³»
ä½¿ç”¨è·¯ä¾§ç›¸æœºç»™ç‚¹äº‘ç€è‰²ï¼Œç„¶åæŠ•å½±åˆ°è½¦ç«¯7ä¸ªç›¸æœº
"""

import json
import yaml
import numpy as np
import cv2
import open3d as o3d
from pathlib import Path
import argparse
from scipy.spatial.transform import Rotation as R
import warnings
import time
from concurrent.futures import ThreadPoolExecutor
import threading
import sys
import os
import re

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥ common_utilsï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
import common_utils

warnings.filterwarnings('ignore', category=UserWarning)

# è·¯ä¾§pinholeç›¸æœºé…ç½®
ROADSIDE_CAMERAS = {
    0: {"name": "pinhole0", "cam_id": "3", "desc": "è·¯ä¾§ç›¸æœº3"},
    1: {"name": "pinhole1", "cam_id": "6", "desc": "è·¯ä¾§ç›¸æœº6"},
    2: {"name": "pinhole2", "cam_id": "9", "desc": "è·¯ä¾§ç›¸æœº9"},
    3: {"name": "pinhole3", "cam_id": "0", "desc": "è·¯ä¾§ç›¸æœº0"}
}

# è½¦ç«¯ç›¸æœºé…ç½®
VEHICLE_CAMERAS = {
    1: {"name": "FN", "desc": "å‰è§†çª„è§’30Â°", "resolution": (3840, 2160)},
    2: {"name": "FW", "desc": "å‰è§†å¹¿è§’120Â°", "resolution": (3840, 2160)},
    3: {"name": "FL", "desc": "å·¦å‰è§†120Â°", "resolution": (3840, 2160)},
    4: {"name": "FR", "desc": "å³å‰è§†120Â°", "resolution": (3840, 2160)},
    5: {"name": "RL", "desc": "å·¦åè§†60Â°", "resolution": (1920, 1080)},
    6: {"name": "RR", "desc": "å³åè§†60Â°", "resolution": (1920, 1080)},
    7: {"name": "RN", "desc": "åè§†60Â°", "resolution": (1920, 1080)}
}

def quaternion_to_rotation_matrix(q):
    """å››å…ƒæ•°è½¬æ—‹è½¬çŸ©é˜µ"""
    x, y, z, w = q
    R = np.array([
        [1-2*(y*y+z*z), 2*(x*y-z*w), 2*(x*z+y*w)],
        [2*(x*y+z*w), 1-2*(x*x+z*z), 2*(y*z-x*w)],
        [2*(x*z-y*w), 2*(y*z+x*w), 1-2*(x*x+y*y)]
    ])
    return R

def rodrigues_to_R(rvec3):
    """ç½—å¾·é‡Œæ ¼æ–¯å‘é‡è½¬æ—‹è½¬çŸ©é˜µ"""
    r = np.asarray(rvec3, dtype=np.float64).reshape(3)
    R, _ = cv2.Rodrigues(r)
    return R

def find_gt_image(gt_images_folder, camera_name, timestamp_ms):
    """æ‰¾åˆ°æœ€æ¥è¿‘çš„çœŸå€¼å›¾ç‰‡"""
    camera_folder = Path(gt_images_folder) / camera_name
    if not camera_folder.exists():
        return None

    target_timestamp_us = timestamp_ms * 1000

    jpg_files = list(camera_folder.glob("*.jpg"))
    closest_file = None
    min_diff = float('inf')

    for jpg_file in jpg_files:
        match = re.search(r'_(\d+)\.(\d+)\.jpg$', jpg_file.name)
        if match:
            seconds = int(match.group(1))
            microseconds = int(match.group(2))
            timestamp_us = seconds * 1000000 + microseconds

            diff = abs(timestamp_us - target_timestamp_us)
            if diff < min_diff:
                min_diff = diff
                closest_file = jpg_file

    return closest_file

def find_roadside_image(roadside_images_folder, pinhole_name, cam_id, timestamp_ms, max_time_diff_ms=1000):
    """æ‰¾åˆ°è·¯ä¾§ç›¸æœºå›¾åƒ
    Args:
        max_time_diff_ms: æœ€å¤§å…è®¸çš„æ—¶é—´å·®ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤1000ms
    """
    camera_folder = Path(roadside_images_folder) / pinhole_name
    if not camera_folder.exists():
        return None, None

    # å›¾åƒæ ¼å¼: cam{cam_id}_{timestamp}.png
    expected_name = f"cam{cam_id}_{timestamp_ms}.png"
    img_path = camera_folder / expected_name

    if img_path.exists():
        return img_path, 0

    # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ‰¾æœ€æ¥è¿‘çš„æ—¶é—´æˆ³
    pattern = f"cam{cam_id}_*.png"
    png_files = list(camera_folder.glob(pattern))

    if not png_files:
        return None, None

    closest_file = None
    min_diff = float('inf')

    for png_file in png_files:
        match = re.search(r'_(\d+)\.png$', png_file.name)
        if match:
            file_timestamp = int(match.group(1))
            diff = abs(file_timestamp - timestamp_ms)
            if diff < min_diff:
                min_diff = diff
                closest_file = png_file

    # åªè¿”å›æ—¶é—´å·®åœ¨å…è®¸èŒƒå›´å†…çš„å›¾åƒ
    if closest_file and min_diff <= max_time_diff_ms:
        return closest_file, min_diff

    return None, min_diff if closest_file else None


class BlurProjectorMultiThread:
    def __init__(self, roadside_calib_path, roadside_images_folder, vehicle_calib_folder,
                 gt_images_folder, transforms):
        """
        åˆå§‹åŒ–æŠ•å½±å™¨

        Args:
            roadside_calib_path: è·¯ä¾§æ ‡å®šæ–‡ä»¶è·¯å¾„
            roadside_images_folder: è·¯ä¾§å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„
            vehicle_calib_folder: è½¦ç«¯æ ‡å®šæ–‡ä»¶å¤¹è·¯å¾„
            gt_images_folder: çœŸå€¼å›¾åƒæ–‡ä»¶å¤¹
            transforms: world2lidar å˜æ¢çŸ©é˜µåˆ—è¡¨
        """
        with open(roadside_calib_path, 'r') as f:
            self.roadside_calib = json.load(f)
        self.roadside_images_folder = Path(roadside_images_folder)
        self.vehicle_calib_folder = Path(vehicle_calib_folder)
        self.gt_images_folder = Path(gt_images_folder)
        self.transforms = transforms
        self.roadside_camera_params = {}
        self.vehicle_camera_params = {}
        self.camera_poses = {}

        # è®¾ç½®OpenCVçº¿ç¨‹æ•°
        cv2.setNumThreads(0)  # è®©æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹ä½¿ç”¨OpenCV

    def get_world2lidar_transform(self, timestamp_ms):
        """
        è·å– world2lidar å˜æ¢çŸ©é˜µ

        Args:
            timestamp_ms: æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰

        Returns:
            rotation_vector: æ—‹è½¬å‘é‡ï¼ˆç½—å¾·é‡Œæ ¼æ–¯ï¼‰
            translation: å¹³ç§»å‘é‡
        """
        # æŸ¥æ‰¾æœ€æ¥è¿‘çš„å˜æ¢çŸ©é˜µ
        transform = common_utils.find_closest_transform(timestamp_ms, self.transforms)

        if transform is None:
            raise ValueError(f"æœªæ‰¾åˆ°æ—¶é—´æˆ³ {timestamp_ms} å¯¹åº”çš„å˜æ¢çŸ©é˜µ")

        # æå–æ—‹è½¬å’Œå¹³ç§»
        rotation = np.array(transform['world2lidar']['rotation']).reshape((3, 1))
        translation = np.array(transform['world2lidar']['translation']).reshape((3, 1))

        return rotation, translation

    def load_roadside_camera_params(self, pinhole_id):
        """åŠ è½½è·¯ä¾§ç›¸æœºå‚æ•°"""
        cam_id = ROADSIDE_CAMERAS[pinhole_id]["cam_id"]
        cam_config = self.roadside_calib["camera"][cam_id]

        K = np.asarray(cam_config["intri"], dtype=np.float64).reshape(3, 3)
        D = np.asarray(cam_config.get("distor", []), dtype=np.float64).reshape(-1) if "distor" in cam_config else None
        is_fisheye = bool(cam_config.get("isFish", 0))

        R_V2C = rodrigues_to_R(cam_config["virtualLidarToCam"]["rotate"])
        t_V2C = np.asarray(cam_config["virtualLidarToCam"]["trans"], dtype=np.float64).reshape(3, 1)

        if is_fisheye:
            resolution = tuple(self.roadside_calib["imgSize"]["fish"])
        else:
            resolution = tuple(self.roadside_calib["imgSize"]["notFish"])

        self.roadside_camera_params[pinhole_id] = {
            'K': K,
            'D': D,
            'R_V2C': R_V2C,
            't_V2C': t_V2C,
            'is_fisheye': is_fisheye,
            'resolution': resolution,
            'cam_id': cam_id
        }

        return K, D, R_V2C, t_V2C, is_fisheye

    def load_vehicle_camera_params(self, cam_id):
        """åŠ è½½è½¦ç«¯ç›¸æœºå‚æ•°ï¼ˆä½¿ç”¨å›ºå®šæ ‡å®šè·¯å¾„ï¼‰"""
        with open(self.vehicle_calib_folder / f"camera_{cam_id:02d}_intrinsics.yaml", 'r') as f:
            intrinsics = yaml.safe_load(f)
        K = np.array(intrinsics['K']).reshape(3, 3)
        D = np.array(intrinsics['D'])

        with open(self.vehicle_calib_folder / f"camera_{cam_id:02d}_extrinsics.yaml", 'r') as f:
            extrinsics = yaml.safe_load(f)

        transform = extrinsics['transform']
        q = [transform['rotation']['x'], transform['rotation']['y'],
             transform['rotation']['z'], transform['rotation']['w']]
        t = np.array([transform['translation']['x'],
                     transform['translation']['y'],
                     transform['translation']['z']])
        R_cam = quaternion_to_rotation_matrix(q)

        self.camera_poses[cam_id] = {
            'R': R_cam,
            't': t,
            'label': extrinsics.get('label', ''),
            'name': VEHICLE_CAMERAS[cam_id]['name']
        }

        self.vehicle_camera_params[cam_id] = {
            'K': K,
            'D': D,
            'resolution': VEHICLE_CAMERAS[cam_id]["resolution"]
        }

        return K, D, R_cam, t

    def colorize_pointcloud_from_roadside(self, points, timestamp_ms):
        """ä½¿ç”¨è·¯ä¾§ç›¸æœºç»™ç‚¹äº‘ç€è‰²
        Args:
            points: ç‚¹äº‘åæ ‡ (N, 3) - åœ¨ä¸–ç•Œåæ ‡ç³»
            timestamp_ms: æ—¶é—´æˆ³
        Returns:
            colors: ç‚¹äº‘é¢œè‰² (N, 3) - RGBå€¼åœ¨[0,1]èŒƒå›´
        """
        N = len(points)
        colors = np.zeros((N, 3), dtype=np.float32)
        color_counts = np.zeros(N, dtype=np.int32)

        # åŠ è½½æ‰€æœ‰è·¯ä¾§ç›¸æœºå‚æ•°
        for pinhole_id in range(4):
            if pinhole_id not in self.roadside_camera_params:
                self.load_roadside_camera_params(pinhole_id)

        # éå†æ¯ä¸ªè·¯ä¾§ç›¸æœº
        for pinhole_id in range(4):
            pinhole_name = ROADSIDE_CAMERAS[pinhole_id]['name']
            cam_id = ROADSIDE_CAMERAS[pinhole_id]['cam_id']

            # æŸ¥æ‰¾å›¾åƒ
            img_path, time_diff = find_roadside_image(
                self.roadside_images_folder, pinhole_name, cam_id, timestamp_ms
            )
            if not img_path:
                print(f"  è­¦å‘Š: æœªæ‰¾åˆ°{pinhole_name}çš„å›¾åƒ (æŸ¥æ‰¾cam{cam_id}_{timestamp_ms}.png)")
                continue

            # è¯»å–å›¾åƒ
            img = cv2.imread(str(img_path))
            if img is None:
                print(f"  è­¦å‘Š: æ— æ³•è¯»å–{img_path}")
                continue

            if time_diff > 0:
                print(f"  {pinhole_name}: ä½¿ç”¨å›¾åƒ {img_path.name} (æ—¶é—´å·®: {time_diff}ms)")

            # è·å–ç›¸æœºå‚æ•°
            params = self.roadside_camera_params[pinhole_id]
            K = params['K']
            D = params['D']
            R_V2C = params['R_V2C']
            t_V2C = params['t_V2C']
            is_fisheye = params['is_fisheye']
            img_w, img_h = params['resolution']

            # ä¸–ç•Œåæ ‡ç³» â†’ VirtualLidaråæ ‡ç³»ï¼ˆè·¯ä¾§ç›¸æœºåæ ‡ï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ç‚¹äº‘å·²ç»åœ¨VirtualLidaråæ ‡ç³»ï¼Œå¦‚æœä¸æ˜¯éœ€è¦è½¬æ¢
            points_vlidar = points  # å‡è®¾merged_pcdå·²ç»åœ¨VirtualLidaråæ ‡ç³»

            # VirtualLidar â†’ ç›¸æœºåæ ‡ç³»
            points_cam = (R_V2C @ points_vlidar.T).T + t_V2C.T

            # è¿‡æ»¤èƒŒåçš„ç‚¹
            valid_mask = points_cam[:, 2] > 0.1
            if not np.any(valid_mask):
                continue

            valid_indices = np.where(valid_mask)[0]
            points_valid = points_cam[valid_mask]

            # æŠ•å½±åˆ°å›¾åƒå¹³é¢
            if D is not None and len(D) > 0:
                # ä½¿ç”¨ç•¸å˜æ¨¡å‹æŠ•å½±
                rvec = np.zeros(3)
                tvec = np.zeros(3)

                if is_fisheye and len(D) >= 4:
                    uv, _ = cv2.fisheye.projectPoints(
                        points_valid.reshape(-1, 1, 3),
                        rvec, tvec, K, D[:4]
                    )
                else:
                    uv, _ = cv2.projectPoints(
                        points_valid.reshape(-1, 1, 3),
                        rvec, tvec, K, D
                    )
                uv = uv.reshape(-1, 2)
            else:
                # æ— ç•¸å˜ï¼Œç›´æ¥æŠ•å½±
                uv_homogeneous = (K @ points_valid.T).T
                uv = uv_homogeneous[:, :2] / uv_homogeneous[:, 2:3]

            # è¿‡æ»¤å›¾åƒå†…çš„ç‚¹
            valid_proj_mask = (uv[:, 0] >= 0) & (uv[:, 0] < img_w) & \
                             (uv[:, 1] >= 0) & (uv[:, 1] < img_h)

            if not np.any(valid_proj_mask):
                continue

            valid_proj_indices = valid_indices[valid_proj_mask]
            uv_valid = uv[valid_proj_mask].astype(int)

            # ä»å›¾åƒä¸­æå–é¢œè‰²
            for i, (u, v) in enumerate(uv_valid):
                point_idx = valid_proj_indices[i]
                # OpenCVå›¾åƒæ˜¯BGRï¼Œè½¬ä¸ºRGB
                bgr = img[v, u]
                rgb = bgr[::-1] / 255.0  # BGR->RGB, å½’ä¸€åŒ–åˆ°[0,1]
                colors[point_idx] += rgb
                color_counts[point_idx] += 1

            print(f"  {pinhole_name}: ç€è‰²äº† {len(uv_valid)} ä¸ªç‚¹")

        # å¹³å‡å¤šä¸ªç›¸æœºçš„é¢œè‰²
        colored_mask = color_counts > 0
        colors[colored_mask] /= color_counts[colored_mask, np.newaxis]

        # æœªç€è‰²çš„ç‚¹ä½¿ç”¨ç°è‰²
        uncolored_count = np.sum(~colored_mask)
        if uncolored_count > 0:
            colors[~colored_mask] = 0.5
            print(f"  è­¦å‘Š: {uncolored_count} ä¸ªç‚¹æœªè¢«è·¯ä¾§ç›¸æœºç€è‰²ï¼ˆä½¿ç”¨ç°è‰²ï¼‰")

        colored_count = np.sum(colored_mask)
        print(f"  æ€»è®¡: {colored_count}/{N} ä¸ªç‚¹æˆåŠŸç€è‰² ({colored_count/N*100:.1f}%)")

        return colors

    def undistort_gt_image(self, gt_image_path, cam_id, output_path):
        """å¯¹çœŸå€¼å›¾åƒè¿›è¡Œå»ç•¸å˜"""
        if not gt_image_path or not gt_image_path.exists():
            return False

        # è¯»å–å›¾åƒ
        img = cv2.imread(str(gt_image_path))
        if img is None:
            return False

        # è·å–ç›¸æœºå‚æ•°
        K = self.vehicle_camera_params[cam_id]['K']
        D = self.vehicle_camera_params[cam_id]['D']
        w, h = self.vehicle_camera_params[cam_id]['resolution']

        # å¯¹äºé±¼çœ¼ç›¸æœºï¼ˆFL, FR, FWï¼‰ï¼Œä½¿ç”¨ç‰¹æ®Šçš„å»ç•¸å˜æ–¹æ³•
        if cam_id in [2, 3, 4] and np.max(np.abs(D)) > 1:
            # é±¼çœ¼ç›¸æœºå»ç•¸å˜
            new_K = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(
                K, D[:4], (w, h), np.eye(3), balance=0.0
            )

            # è®¡ç®—æ˜ å°„
            map1, map2 = cv2.fisheye.initUndistortRectifyMap(
                K, D[:4], np.eye(3), new_K, (w, h), cv2.CV_16SC2
            )

            # åº”ç”¨å»ç•¸å˜
            undistorted = cv2.remap(img, map1, map2, cv2.INTER_LINEAR)
        else:
            # æ™®é€šç›¸æœºå»ç•¸å˜
            new_K, roi = cv2.getOptimalNewCameraMatrix(K, D, (w, h), 0, (w, h))
            undistorted = cv2.undistort(img, K, D, None, new_K)

        # ä¿å­˜å»ç•¸å˜å›¾åƒ
        cv2.imwrite(str(output_path), undistorted, [cv2.IMWRITE_JPEG_QUALITY, 100])
        return True

    def project_to_camera_undistorted(self, points, colors, rotate_world2lidar,
                                     trans_world2lidar, cam_id):
        """
        æŠ•å½±åˆ°å»ç•¸å˜çš„ç›¸æœºå¹³é¢

        å˜æ¢æµç¨‹ï¼šä¸–ç•Œåæ ‡ç³» â†’ LiDARåæ ‡ç³» â†’ ç›¸æœºåæ ‡ç³» â†’ å›¾åƒåæ ‡ç³»
        """
        cam_info = VEHICLE_CAMERAS[cam_id]
        img_w, img_h = cam_info["resolution"]

        K = self.vehicle_camera_params[cam_id]['K']
        D = self.vehicle_camera_params[cam_id]['D']
        R_cam2lidar = self.camera_poses[cam_id]['R']
        t_cam2lidar = self.camera_poses[cam_id]['t']

        # æ­¥éª¤1: ä¸–ç•Œåæ ‡ç³» â†’ LiDARåæ ‡ç³»
        points_lidar = common_utils.transform_points_to_lidar(
            points[:, :3],
            {'world2lidar': {
                'rotation': rotate_world2lidar.flatten().tolist(),
                'translation': trans_world2lidar.flatten().tolist()
            }}
        )

        # æ­¥éª¤2: LiDARåæ ‡ç³» â†’ ç›¸æœºåæ ‡ç³»
        R_lidar2cam = R_cam2lidar.T
        t_lidar2cam = -R_cam2lidar.T @ t_cam2lidar

        points_cam = (R_lidar2cam @ points_lidar.T).T + t_lidar2cam

        # è¿‡æ»¤èƒŒåçš„ç‚¹
        valid = points_cam[:, 2] > 0.1
        if not np.any(valid):
            return np.zeros((img_h, img_w, 3), dtype=np.uint8), 0

        points_valid = points_cam[valid]
        colors_valid = colors[valid] if colors is not None else None

        # æ­¥éª¤3: ç›¸æœºåæ ‡ç³» â†’ å›¾åƒåæ ‡ç³»ï¼ˆå»ç•¸å˜æŠ•å½±ï¼‰
        if cam_id in [2, 3, 4] and np.max(np.abs(D)) > 1:
            # é±¼çœ¼ç›¸æœºï¼šä½¿ç”¨è°ƒæ•´åçš„å†…å‚
            new_K = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(
                K, D[:4], (img_w, img_h), np.eye(3), balance=0.0
            )
        else:
            # æ™®é€šç›¸æœºï¼šä½¿ç”¨ä¼˜åŒ–åçš„å†…å‚
            new_K, _ = cv2.getOptimalNewCameraMatrix(K, D, (img_w, img_h), 0, (img_w, img_h))

        # ä½¿ç”¨æ–°çš„å†…å‚è¿›è¡Œçº¿æ€§æŠ•å½±
        uv_homogeneous = (new_K @ points_valid.T).T
        z_proj = uv_homogeneous[:, 2]
        uv = (uv_homogeneous[:, :2] / z_proj[:, np.newaxis]).astype(int)

        # è¿‡æ»¤æœ‰æ•ˆæŠ•å½±ç‚¹
        valid_proj = (uv[:, 0] >= 0) & (uv[:, 0] < img_w) & \
                    (uv[:, 1] >= 0) & (uv[:, 1] < img_h)
        uv_valid = uv[valid_proj]

        # åˆ›å»ºå›¾åƒ
        img = np.zeros((img_h, img_w, 3), dtype=np.uint8)

        if len(uv_valid) > 0:
            proj_colors = (colors_valid[valid_proj] * 255).astype(np.uint8)
            # ä½¿ç”¨cv2.circleç»˜åˆ¶åŠå¾„ä¸º2çš„åœ†
            for (u, v), color in zip(uv_valid, proj_colors):
                cv2.circle(img, (u, v), 2,
                         (int(color[2]), int(color[1]), int(color[0])), -1)

        return img, len(uv_valid)

    def process_single_camera(self, cam_id, points, colors, rotate_world2lidar,
                             trans_world2lidar, timestamp_ms, proj_dir, gt_dir,
                             compare_dir, overlay_dir):
        """å¤„ç†å•ä¸ªç›¸æœºï¼ˆç”¨äºå¤šçº¿ç¨‹ï¼‰"""
        cam_name = VEHICLE_CAMERAS[cam_id]['name']

        results = {'cam_name': cam_name, 'proj_img': None, 'gt_img': None, 'count': 0}

        # å¤„ç†GTå›¾åƒ
        gt_image_path = find_gt_image(self.gt_images_folder, cam_name, timestamp_ms)
        if gt_image_path:
            gt_output = gt_dir / f"{cam_name}.jpg"
            if self.undistort_gt_image(gt_image_path, cam_id, gt_output):
                results['gt_img'] = cv2.imread(str(gt_output))

        # æŠ•å½±ç‚¹äº‘
        proj_img, count = self.project_to_camera_undistorted(
            points, colors, rotate_world2lidar, trans_world2lidar, cam_id
        )
        proj_output = proj_dir / f"{cam_name}.jpg"
        cv2.imwrite(str(proj_output), proj_img, [cv2.IMWRITE_JPEG_QUALITY, 100])
        results['proj_img'] = proj_img
        results['count'] = count

        # ç”Ÿæˆcompareå›¾ï¼ˆGTå’ŒPROJå·¦å³å¯¹æ¯”ï¼‰
        if results['gt_img'] is not None and results['proj_img'] is not None:
            gt_img = results['gt_img']
            compare_img = np.hstack([gt_img, proj_img])
            compare_output = compare_dir / f"{cam_name}.jpg"
            cv2.imwrite(str(compare_output), compare_img, [cv2.IMWRITE_JPEG_QUALITY, 100])

        # ç”Ÿæˆoverlayå›¾ï¼ˆæŠ•å½±å åŠ åˆ°GTä¸Šï¼‰
        if results['gt_img'] is not None and results['proj_img'] is not None:
            gt_img = results['gt_img']
            # å°†æŠ•å½±ç»“æœå åŠ åˆ°GTä¸Šï¼ˆæŠ•å½±éé»‘è‰²åƒç´ è¦†ç›–åˆ°GTä¸Šï¼‰
            overlay_img = gt_img.copy()
            # æ‰¾åˆ°æŠ•å½±å›¾ä¸­éé»‘è‰²çš„åƒç´ ï¼ˆBGRæ‰€æœ‰é€šé“éƒ½å¤§äºé˜ˆå€¼ï¼‰
            mask = np.any(proj_img > 10, axis=2)
            overlay_img[mask] = proj_img[mask]
            overlay_output = overlay_dir / f"{cam_name}.jpg"
            cv2.imwrite(str(overlay_output), overlay_img, [cv2.IMWRITE_JPEG_QUALITY, 100])

        return results

    def process_single_frame(self, pcd_path, output_dir, timestamp_ms, num_threads=7):
        """
        å¤„ç†å•å¸§æ•°æ®ï¼ˆå¤šçº¿ç¨‹ï¼‰

        Args:
            pcd_path: PCDæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            timestamp_ms: æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
            num_threads: çº¿ç¨‹æ•°
        """
        output_dir = Path(output_dir)
        proj_dir = output_dir / "proj"
        gt_dir = output_dir / "gt"
        compare_dir = output_dir / "compare"
        overlay_dir = output_dir / "overlay"

        proj_dir.mkdir(parents=True, exist_ok=True)
        gt_dir.mkdir(parents=True, exist_ok=True)
        compare_dir.mkdir(parents=True, exist_ok=True)
        overlay_dir.mkdir(parents=True, exist_ok=True)

        # 1. åŠ è½½ç‚¹äº‘
        pcd = o3d.io.read_point_cloud(str(pcd_path))
        points = np.asarray(pcd.points)

        # 2. è·å– world2lidar å˜æ¢
        try:
            rotate_world2lidar, trans_world2lidar = self.get_world2lidar_transform(timestamp_ms)
        except ValueError as e:
            print(f"âŒ {e}")
            return False

        # 3. ä½¿ç”¨è·¯ä¾§ç›¸æœºç»™ç‚¹äº‘ç€è‰²
        print(f"ğŸ¨ ä½¿ç”¨è·¯ä¾§ç›¸æœºç€è‰²ç‚¹äº‘...")
        colors = self.colorize_pointcloud_from_roadside(points, timestamp_ms)

        # 4. åŠ è½½è½¦ç«¯ç›¸æœºå‚æ•°
        for cam_id in range(1, 8):
            if cam_id not in self.vehicle_camera_params:
                self.load_vehicle_camera_params(cam_id)

        # 5. å¤šçº¿ç¨‹å¤„ç†æ¯ä¸ªè½¦ç«¯ç›¸æœº
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = []
            for cam_id in range(1, 8):
                future = executor.submit(
                    self.process_single_camera,
                    cam_id, points, colors, rotate_world2lidar,
                    trans_world2lidar, timestamp_ms, proj_dir, gt_dir,
                    compare_dir, overlay_dir
                )
                futures.append(future)

            # æ”¶é›†ç»“æœ
            for future in futures:
                result = future.result()

        return True


def main():
    parser = argparse.ArgumentParser(description="å¤šçº¿ç¨‹ä¼˜åŒ–å»ç•¸å˜ç‰ˆæŠ•å½± V2 - BluræŠ•å½±")
    parser.add_argument("--roadside-calib", type=str, required=True)
    parser.add_argument("--roadside-images", type=str, required=True)
    parser.add_argument("--vehicle-calib", type=str, required=True)
    parser.add_argument("--gt-images", type=str, required=True)
    parser.add_argument("--pcd", type=str, required=True)
    parser.add_argument("--transform-json", type=str, required=True)
    parser.add_argument("--output-dir", type=str, required=True)
    parser.add_argument("--timestamp", type=int, required=True)
    parser.add_argument("--num-threads", type=int, default=7, help="æ¯å¸§ä½¿ç”¨çš„çº¿ç¨‹æ•°")

    args = parser.parse_args()

    # åŠ è½½å˜æ¢çŸ©é˜µ
    transforms = common_utils.load_world2lidar_transforms(args.transform_json)

    projector = BlurProjectorMultiThread(
        args.roadside_calib, args.roadside_images, args.vehicle_calib,
        args.gt_images, transforms
    )
    projector.process_single_frame(
        args.pcd, args.output_dir, args.timestamp, args.num_threads
    )

if __name__ == "__main__":
    main()
